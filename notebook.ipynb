{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import neurogym as ngym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeuroGym Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'PerceptualDecisionMaking-v0'\n",
    "kwargs = {'dt': 20, 'timing': {'stimulus': 1000}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has shape (SeqLen, Batch, Dim) = torch.Size([100, 16, 3])\n",
      "Target has shape (SeqLen, Batch) = (100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Make supervised dataset\n",
    "seq_len = 100\n",
    "batch_size = 16\n",
    "#Create the dataset (Hover over ngym.Dataset to see input arguments)\n",
    "dataset = ngym.Dataset(task_name, env_kwargs=kwargs, seq_len=seq_len, batch_size=batch_size)\n",
    "env = dataset.env\n",
    "\n",
    "# Generate one batch of data when called\n",
    "inputs, target = dataset()\n",
    "inputs = torch.from_numpy(inputs).type(torch.float)\n",
    "\n",
    "input_size = env.observation_space.shape[0]\n",
    "output_size = env.action_space.n\n",
    "\n",
    "print('Input has shape (SeqLen, Batch, Dim) =', inputs.shape)\n",
    "print('Target has shape (SeqLen, Batch) =', target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, dataset):\n",
    "    \"\"\"Simple helper function to train the model.\n",
    "\n",
    "    Args:\n",
    "        net: a pytorch nn.Module module\n",
    "        dataset: a dataset object that when called produce a (input, target output) pair\n",
    "\n",
    "    Returns:\n",
    "        net: network object after training\n",
    "    \"\"\"\n",
    "    # Use Adam optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    start_time = time.time()\n",
    "    # Loop over training batches\n",
    "    print('Training network...')\n",
    "    for i in range(2000):\n",
    "        # Generate input and target, convert to pytorch tensor\n",
    "        inputs, labels = dataset()\n",
    "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
    "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
    "\n",
    "        # boiler plate pytorch training:\n",
    "        optimizer.zero_grad()   # zero the gradient buffers\n",
    "        output, _ = net(inputs)\n",
    "        # Reshape to (SeqLen x Batch, OutputSize)\n",
    "        output = output.view(-1, output_size)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "        # Compute the running loss every 100 steps\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            running_loss /= 100\n",
    "            print('Step {}, Loss {:0.4f}, Time {:0.1f}s'.format(\n",
    "                i+1, running_loss, time.time() - start_time))\n",
    "            running_loss = 0\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Leaky RNN (from notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeakyRNN(nn.Module):\n",
    "    \"\"\"Leaky RNN.\n",
    "\n",
    "    Parameters:\n",
    "        input_size: Number of input neurons\n",
    "        hidden_size: Number of hidden neurons\n",
    "        dt: discretization time step in ms.\n",
    "            If None, dt equals time constant tau\n",
    "\n",
    "    Inputs:\n",
    "        input: tensor of shape (seq_len, batch, input_size)\n",
    "        hidden: tensor of shape (batch, hidden_size), initial hidden activity\n",
    "            if None, hidden is initialized through self.init_hidden()\n",
    "\n",
    "    Outputs:\n",
    "        output: tensor of shape (seq_len, batch, hidden_size)\n",
    "        hidden: tensor of shape (batch, hidden_size), final hidden activity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, dt=None, **kwargs):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.tau = 100\n",
    "        if dt is None:\n",
    "            alpha = 1\n",
    "        else:\n",
    "            alpha = dt / self.tau\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.input2h = nn.Linear(input_size, hidden_size)\n",
    "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def init_hidden(self, input_shape):\n",
    "        batch_size = input_shape[1]\n",
    "        return torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "    def recurrence(self, input, hidden):\n",
    "        \"\"\"Run network for one time step.\n",
    "\n",
    "        Inputs:\n",
    "            input: tensor of shape (batch, input_size)\n",
    "            hidden: tensor of shape (batch, hidden_size)\n",
    "\n",
    "        Outputs:\n",
    "            h_new: tensor of shape (batch, hidden_size),\n",
    "                network activity at the next time step\n",
    "        \"\"\"\n",
    "        h_new = torch.relu(self.input2h(input) + self.h2h(hidden))\n",
    "\n",
    "        #implement how much the previous hidden layer activity should be maintained in the new activity\n",
    "        h_new = hidden * (1 - self.alpha) + h_new * self.alpha\n",
    "        return h_new\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        \"\"\"Propogate input through the network.\"\"\"\n",
    "\n",
    "        # If hidden activity is not provided, initialize it\n",
    "        if hidden is None:\n",
    "            hidden = self.init_hidden(input.shape).to(input.device)\n",
    "\n",
    "        # Loop through time\n",
    "        output = []\n",
    "        steps = range(input.size(0))\n",
    "        for i in steps:\n",
    "            hidden = self.recurrence(input[i], hidden)\n",
    "            output.append(hidden)\n",
    "\n",
    "        # Stack together output from all time steps\n",
    "        output = torch.stack(output, dim=0)  # (seq_len, batch, hidden_size)\n",
    "        return output, hidden\n",
    "\n",
    "\n",
    "class RNNNet(nn.Module):\n",
    "    \"\"\"Recurrent network model.\n",
    "\n",
    "    Parameters:\n",
    "        input_size: int, input size\n",
    "        hidden_size: int, hidden size\n",
    "        output_size: int, output size\n",
    "\n",
    "    Inputs:\n",
    "        x: tensor of shape (Seq Len, Batch, Input size)\n",
    "\n",
    "    Outputs:\n",
    "        out: tensor of shape (Seq Len, Batch, Output size)\n",
    "        rnn_output: tensor of shape (Seq Len, Batch, Hidden size)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Leaky RNN\n",
    "        self.rnn = LeakyRNN(input_size, hidden_size, **kwargs)\n",
    "\n",
    "        # Add a Linear output layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_output, _ = self.rnn(x)\n",
    "        out = self.fc(rnn_output)\n",
    "        return out, rnn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNNet(\n",
      "  (rnn): LeakyRNN(\n",
      "    (input2h): Linear(in_features=3, out_features=128, bias=True)\n",
      "    (h2h): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n",
      "Training network...\n",
      "Step 100, Loss 0.1916, Time 2.9s\n",
      "Step 200, Loss 0.0581, Time 5.9s\n",
      "Step 300, Loss 0.0499, Time 8.9s\n",
      "Step 400, Loss 0.0411, Time 11.9s\n",
      "Step 500, Loss 0.0303, Time 15.2s\n",
      "Step 600, Loss 0.0317, Time 18.3s\n",
      "Step 700, Loss 0.0315, Time 21.3s\n",
      "Step 800, Loss 0.0317, Time 24.5s\n",
      "Step 900, Loss 0.0276, Time 27.9s\n",
      "Step 1000, Loss 0.0251, Time 31.0s\n",
      "Step 1100, Loss 0.0250, Time 34.5s\n",
      "Step 1200, Loss 0.0293, Time 37.8s\n",
      "Step 1300, Loss 0.0277, Time 41.1s\n",
      "Step 1400, Loss 0.0241, Time 44.5s\n",
      "Step 1500, Loss 0.0238, Time 48.0s\n",
      "Step 1600, Loss 0.0247, Time 51.4s\n",
      "Step 1700, Loss 0.0234, Time 55.0s\n",
      "Step 1800, Loss 0.0237, Time 58.5s\n",
      "Step 1900, Loss 0.0251, Time 61.9s\n",
      "Step 2000, Loss 0.0241, Time 65.5s\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the network and print information\n",
    "hidden_size = 128\n",
    "\n",
    "# Create an instance of the Class RNNNet\n",
    "net = RNNNet(input_size, hidden_size, output_size, dt=env.dt)\n",
    "print(net)\n",
    "\n",
    "net = train_model(net, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Brain Inspired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EDF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
